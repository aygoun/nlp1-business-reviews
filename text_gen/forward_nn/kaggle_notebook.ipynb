{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T22:33:02.997288Z",
     "iopub.status.busy": "2025-05-10T22:33:02.996939Z",
     "iopub.status.idle": "2025-05-10T22:33:04.795747Z",
     "shell.execute_reply": "2025-05-10T22:33:04.795123Z",
     "shell.execute_reply.started": "2025-05-10T22:33:02.997265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/large-yaml/reviews2.pkl\n",
      "/kaggle/input/yelp-small/yelp_subset_review.json\n",
      "/kaggle/input/150-epochs-gen-text/keras/default/1/yelp_review_generator-43 perplexity.h5\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# DATA_SET_ZIP = \"/kaggle/input/yelp-full/file.zip\n",
    "# DEST = \"/kaggle/input/yelp-full/unzipped/\"\n",
    "# os.makdirs(DEST)\n",
    "# # Unwip dataset\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile(DATA_SET_ZIP, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(DEST)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T22:33:04.796961Z",
     "iopub.status.busy": "2025-05-10T22:33:04.796578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "DATA_SET = \"/kaggle/input/large-yaml/reviews2.pkl\"\n",
    "MODEL = \"/kaggle/input/150-epochs-gen-text/keras/default/1/yelp_review_generator-43 perplexity.h5\"\n",
    "\n",
    "# Load your Yelp reviews dataset\n",
    "def load_yelp_reviews():\n",
    "    \"\"\"Load the review data from JSON file or JSON Lines format\"\"\"\n",
    "    df = pd.read_pickle(DATA_SET)\n",
    "\n",
    "    print(f\"\\nData Loading Summary:\")\n",
    "    print(f\"Total reviews loaded: {len(df)}\")\n",
    "    print(f\"Columns available: {df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "# Load the reviews\n",
    "reviews = load_yelp_reviews()\n",
    "print(reviews[:10])\n",
    "\n",
    "# Tokenize the text\n",
    "max_words = 5000  # Maximum vocabulary size\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1  # Add 1 for padding token\n",
    "MAX_LEN = 100\n",
    "\n",
    "# Create sequences\n",
    "input_sequences = []\n",
    "\n",
    "\n",
    "for review in reviews:\n",
    "    tokens = tokenizer.texts_to_sequences([review])[0][:MAX_LEN]  # Limit input\n",
    "    for i in range(1, len(tokens)):\n",
    "        input_sequences.append(tokens[: i + 1])\n",
    "\n",
    "\n",
    "# Pad sequences\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=MAX_LEN, padding=\"pre\")\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "max_sequence_len = MAX_LEN\n",
    "\n",
    "# Define model architecture\n",
    "embedding_dim = 100\n",
    "\n",
    "if os.path.exists(MODEL):\n",
    "    print(f\"Loading model from: {MODEL}\")\n",
    "    model = tf.keras.models.load_model(MODEL)\n",
    "else:\n",
    "    print(\"Model not found, creating a new one.\")\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Embedding(max_words, 64, input_length=MAX_LEN - 1),\n",
    "            LSTM(64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(32),\n",
    "            Dropout(0.2),\n",
    "            Dense(max_words, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, max_sequence_len - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:41:01.709586Z",
     "iopub.status.busy": "2025-05-10T13:41:01.708916Z",
     "iopub.status.idle": "2025-05-10T13:41:35.065941Z",
     "shell.execute_reply": "2025-05-10T13:41:35.065135Z",
     "shell.execute_reply.started": "2025-05-10T13:41:01.709549Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">165,000</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │         \u001b[38;5;34m320,000\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_28 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m33,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_29 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)                │         \u001b[38;5;34m165,000\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,440</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m530,440\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">530,440</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m530,440\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m714/714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.2104 - loss: 4.3579\n"
     ]
    }
   ],
   "source": [
    "epochs = 900\n",
    "# Train model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "with tf.device(\"/GPU:0\"):  # On MPS, GPU:0 is the Metal device\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=1024, verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save(f\"yelp_review_generator-epochs_{epochs}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:41:55.140134Z",
     "iopub.status.busy": "2025-05-10T13:41:55.139211Z",
     "iopub.status.idle": "2025-05-10T13:42:01.040835Z",
     "shell.execute_reply": "2025-05-10T13:42:01.040004Z",
     "shell.execute_reply.started": "2025-05-10T13:41:55.140101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The restaurant atmosphere was <OOV> i asked too again but won't have to come back because of the only the service was really good but i was particularly excited with a friendly atmosphere and service when i had in awhile with tiny low environment wishing after we were looking for <OOV> i know because you can have a wait because they do not make them that a lot of place to spend we had no beef as we don't understand that it took another friends with a dinner party <OOV> with when the wait on gulf all eating inside or we were even <OOV>\n"
     ]
    }
   ],
   "source": [
    "# Generate new text\n",
    "def generate(\n",
    "    seed_text, model, tokenizer, max_sequence_len, temperature=1.0, max_length=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate text that continues from the seed_text until an end-of-sentence token is reached.\n",
    "\n",
    "    Args:\n",
    "        seed_text (str): The starting text to continue from\n",
    "        model: The trained model\n",
    "        tokenizer: The tokenizer used during training\n",
    "        max_sequence_len (int): Maximum sequence length used during training\n",
    "        temperature (float): Controls randomness in generation. Higher values increase diversity.\n",
    "        max_length (int): Maximum length of generated text to prevent infinite loops\n",
    "\n",
    "    Returns:\n",
    "        str: The seed_text plus the generated continuation\n",
    "    \"\"\"\n",
    "    # End of sentence tokens\n",
    "    eos_tokens = [\".\", \"!\", \"?\"]\n",
    "\n",
    "    # Current text is the seed text\n",
    "    current_text = seed_text\n",
    "\n",
    "    # Counter to prevent infinite loops\n",
    "    counter = 0\n",
    "\n",
    "    # Generate text until EOS token or max_length is reached\n",
    "    while counter < max_length:\n",
    "        # Tokenize the current text\n",
    "        token_list = tokenizer.texts_to_sequences([current_text])[0]\n",
    "\n",
    "        # Pad the sequence\n",
    "        token_list = pad_sequences(\n",
    "            [token_list], maxlen=max_sequence_len - 1, padding=\"pre\"\n",
    "        )\n",
    "\n",
    "        # Get model prediction (probabilities for next word)\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        # Apply temperature to adjust prediction diversity\n",
    "        predicted_probs = np.log(predicted_probs) / temperature\n",
    "        exp_preds = np.exp(predicted_probs)\n",
    "        predicted_probs = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        # Sample from the probability distribution\n",
    "        predicted_index = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "\n",
    "        # Get the corresponding word\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "\n",
    "        # Add the predicted word to the current text\n",
    "        if output_word != \"\":\n",
    "            current_text += \" \" + output_word\n",
    "\n",
    "            # Check if the last character is an end-of-sentence token\n",
    "            if output_word[-1] in eos_tokens:\n",
    "                break\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    return current_text\n",
    "\n",
    "# Example usage\n",
    "seed_text = \"The restaurant atmosphere was\"\n",
    "generated_text = generate(seed_text, model, tokenizer, max_sequence_len)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:42:01.042424Z",
     "iopub.status.busy": "2025-05-10T13:42:01.042138Z",
     "iopub.status.idle": "2025-05-10T13:42:01.522303Z",
     "shell.execute_reply": "2025-05-10T13:42:01.521530Z",
     "shell.execute_reply.started": "2025-05-10T13:42:01.042403Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 44.74\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_perplexity(model, X, y):\n",
    "    \"\"\"Compute perplexity over a dataset\"\"\"\n",
    "    y_pred = model.predict(X, verbose=0)\n",
    "    probas = y_pred[np.arange(len(y)), y]\n",
    "    log_probs = -np.log(probas + 1e-10)  # avoid log(0)\n",
    "    perplexity = np.exp(np.mean(log_probs))\n",
    "    return perplexity\n",
    "\n",
    "# Example use\n",
    "perplexity_score = compute_perplexity(model, X[:1000], y[:1000])  # use a sample to reduce memory\n",
    "print(f\"Perplexity: {perplexity_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity: 44.21 After 150 epoches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:42:07.524836Z",
     "iopub.status.busy": "2025-05-10T13:42:07.524275Z",
     "iopub.status.idle": "2025-05-10T13:43:08.778720Z",
     "shell.execute_reply": "2025-05-10T13:43:08.777973Z",
     "shell.execute_reply.started": "2025-05-10T13:42:07.524810Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "\n",
      "Seed: My girlfriend and I\n",
      "Generated: My girlfriend and I went on the first night to take serving the large good part and the food was amazing and we had the sandwich <OOV> a big piece of bread my husband ordered the grouper and it wasn't as much bowl about the white salad i have never experienced i try the appetizers my meal was pretty bland and pointing to and we ordered a open sauce from the <OOV> picture of my orleans a thursday while in far from the corner to the five tables and google the smell which was an great bar no corkage platter of the worst items\n",
      "Reference: My girlfriend and I stopped by in Boise for a night and decided to give the fork a try so keep in mind it was our first in only time. Ordered tomato bisque fondue with grilled cheese as an appetizer and that shit went hard as a mothafucka. Shared the coconut rum and curry braised ribs and that she went hard too! Like calm the fuck down y'all! I'm like yoooooo this shit is fuckin delicious\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.2951\n",
      "  ROUGE-2: 0.0331\n",
      "  ROUGE-L: 0.1749\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.2308\n",
      "  BLEU-2: 0.0820\n",
      "  BLEU-3: 0.0524\n",
      "  BLEU-4: 0.0338\n",
      "\n",
      "Seed: Food is amazing, they\n",
      "Generated: Food is amazing, they offer the physical have time buddy off sides salad so if they sit <OOV> the drinks were great fresh and delicious no points flight great place on a evening and it's one of <OOV> hot food food as great the variety of mint it's worth a upgrade when at going back for a 35 time they looked <OOV> to thank you our one go that and we had at the last time we were passing by shorts and all good beers at 6 this place has been a small story i am my <OOV> near salt bravo two stars well\n",
      "Reference: Food is amazing, they even have daily specials that are so worth the visit. Place is usually packed so make sure you reserve a table. Highly recommended for anyone visiting downtown Boise.\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.2029\n",
      "  ROUGE-2: 0.0441\n",
      "  ROUGE-L: 0.1449\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.1154\n",
      "  BLEU-2: 0.0580\n",
      "  BLEU-3: 0.0417\n",
      "  BLEU-4: 0.0284\n",
      "\n",
      "Seed: Went here for a\n",
      "Generated: Went here for a family experience to eat very great decor and <OOV> service was friendly running there area i love check that however with any season because eat downtown but i have never had my favorite experiences about bahama breeze sooner to make up to be one of the best mojitos i have ever been here here at this buffet dish have a margarita you should try the cuban tortillas towards it ate from the quick steak at all of it it wasn't awful but i did not say our actual bar still no <OOV> up key smells made for a early bird\n",
      "Reference: Went here for a bachelorette party dinner. I was very excited to try it because of all the hype I had heard about it. I thought it was....okay.\n",
      "\n",
      "We had reservations for 9:00 pm. The place was busy and really there is not a lot of seating. We didn't get seated until almost 9:30. Annoying. Then as we were ordering our drinks I ordered an Amaretto Sour. She came back and said they didn't have Amaretto. So I ordered a Pepsi & Malibu. She came back and said they didn't have Malibu. WHATTTTTT. I was super annoyed. I shared an order of the Asparagus fries & they were quite delicious. I also had the BAM Sandwich, Looking at all the ingredients I thought I would love it - but it just fell a little short. I think the huge slab of mozzarella was just too over powering. The pesto was good, and the buns were really soft. I did not like having to spend $2 for subbing fries instead of chips. That was also annoying. \n",
      "\n",
      "I dont think I would bring someone else here.\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.2877\n",
      "  ROUGE-2: 0.0483\n",
      "  ROUGE-L: 0.1575\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.1515\n",
      "  BLEU-2: 0.0639\n",
      "  BLEU-3: 0.0343\n",
      "  BLEU-4: 0.0203\n",
      "\n",
      "Seed: Not good service or\n",
      "Generated: Not good service or service and fell near the best my favorite family <OOV> this the long service is really so awesome latin food but from the good restaurants i tried i could assume all different you are totally surprised and unique if i sat down the location was modern and inviting with a glass of chairs well the food was amazing too when we quickly waited to so long by an hour they had gotten in of us and left up our waitress since we had more <OOV> really i could drink just feel completely extremely clean and though we had to admit\n",
      "Reference: Not good service or food.... \n",
      "it was cold my the time it came to us. Also tried to charge me for two cups of coffee because they had to refill my cup! Ha ha. I have had two bad experiences with this place over a 4 year period I think I'll throw in the towel now. For sure Good for people watching and maybe just a drink\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.3256\n",
      "  ROUGE-2: 0.0588\n",
      "  ROUGE-L: 0.1512\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.2115\n",
      "  BLEU-2: 0.1013\n",
      "  BLEU-3: 0.0603\n",
      "  BLEU-4: 0.0376\n",
      "\n",
      "Seed: OMG amazing food! Best\n",
      "Generated: OMG amazing food! Best service the food was tasty which a lot about my wife went with happy hour great the oranges definitely go back in tampa with with service and horrible service when there is <OOV> and a friendly kitchen to hurry out patio after my dog multiple tables on the <OOV> and when they was able to get <OOV> the windows they were not working back for our a day made this of the downstairs night the atmosphere was very quick and the grits roast burger the butter cake came in for 3 <OOV> 1 order at you long gnocchi just please\n",
      "Reference: OMG amazing food!  Best we've had in Boise. If you don't order the butter cake for dessert,  you're making a huge mistake!\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.1860\n",
      "  ROUGE-2: 0.0787\n",
      "  ROUGE-L: 0.1550\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.1154\n",
      "  BLEU-2: 0.0748\n",
      "  BLEU-3: 0.0564\n",
      "  BLEU-4: 0.0357\n",
      "\n",
      "Seed: My wife and I\n",
      "Generated: My wife and I first got open here from that mixto was just and it was always pleasant the waiter wasn't down but made <OOV> for it a refill fully with <OOV> and catch because the guacamole steak was quite nice and delicious i'm not sure it was full of crab and i guess the food itself was delicious and we also ordered a pizza beef empanadas skewers and the grilled cheese topped with peppers the churros might have it you can tell it was a bit spicy what outside good plate lunch <OOV> <OOV> roast spicy flavor and bacon special my mom and\n",
      "Reference: My wife and I love this place! They have great food and it's decently priced, which is impressive since all of the food is local. The burger and short braised ribs are amazing! We love the atmosphere and the service is great!\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.2148\n",
      "  ROUGE-2: 0.0816\n",
      "  ROUGE-L: 0.1745\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.1250\n",
      "  BLEU-2: 0.0779\n",
      "  BLEU-3: 0.0507\n",
      "  BLEU-4: 0.0329\n",
      "\n",
      "Seed: Brought my daughter and\n",
      "Generated: Brought my daughter and come here and it was great never thought by far the best the food buffet great customer staff after my friend <OOV> it will be looking away if i'm coming to the madeira beach located on a popular kind time days and her the specials were good the seating immediately by the rush and told us more for a 1 plan but we only went lol during their trip again industry and sister and eating here with the musicians holiday stay cool view some <OOV> and place came here for seconds the overall service their server is less so prompt\n",
      "Reference: Brought my daughter and her friend (teenagers) here for dinner while while we were visiting from out of state.  When we checked in they said it was a 45 minute wait, however we were seated within 10 minutes. \n",
      "\n",
      " The food was really good. We started with the potato chip appetizer (which I felt should have been free, such as bread at an Italian place or chips/salsa at a Mexican place), and the artichoke appetizer. Both were really good...great dipping sauces. My daughter still felt the need for bread, so we ended up ordering the bread appetizer. Not worth it. It was about four small baguette type slices. On the bright side, dinner was very good. Ordered the Urban Burger with fries for both girls, and they both loved them. I had the grilled cheese with a salad instead of fries, and it certainly didn't disappoint. It had ham, cheese, grilled onions and a spread of some sort. It was excellent. \n",
      "\n",
      "The only downfall of the restaurant was it took way too long to get our main courses. However, one of the managers approached us before we even had the chance to notice and offered us a free appetizer. We didn't take advantage since we'd already had enough starters. Once we had our main courses my daughter asked if we could get their signature dessert, the butter cake, for free instead. The manager said no problem. And it was to die for!  \n",
      "\n",
      "Overall, good food that took a bit long but they were more than willing to compensate for the slowness. I'd definitely eat here again.\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.2819\n",
      "  ROUGE-2: 0.0535\n",
      "  ROUGE-L: 0.1489\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.0900\n",
      "  BLEU-2: 0.0385\n",
      "  BLEU-3: 0.0188\n",
      "  BLEU-4: 0.0107\n",
      "\n",
      "Seed: Amazing food from local\n",
      "Generated: Amazing food from local lee ordered tons of cheese why sit outside i can't purchase a feel this is one of the bar and they offer in philly fine it's terrible the staff to have sure my wife's tipica it was creative <OOV> wasn't the strip <OOV> this was that with it last as many times the drink is delicious and the music is just on the court of two sisters an dinner if you're looking for multiple stuff i have seen the guests when you have to try <OOV> tends to go because of me and casual they are resting out up and\n",
      "Reference: Amazing food from local sources at reasonable prices considering the quality of the food and service, and the location.  Everything we have ever eaten here has been amazing.  And we ALWAYS get the asparagus no matter what because it is amazing :)\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.2133\n",
      "  ROUGE-2: 0.0676\n",
      "  ROUGE-L: 0.1600\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.1442\n",
      "  BLEU-2: 0.0837\n",
      "  BLEU-3: 0.0531\n",
      "  BLEU-4: 0.0341\n",
      "\n",
      "Seed: I have to give\n",
      "Generated: I have to give them a <OOV> most cooking literally in home so i was to call 50 and could have came at a <OOV> and we actually asked their line ordered the dressing a long scramble and gave two other items on the grilled fish everything was delicious as a burger that's the ayce of the touch our second day ever could not give a 2 taco check that that <OOV> charge but we would do to try how good all the food served following bread with the sparkling tea <OOV> we couldn't support eggs pizza sammy it was fine of any really\n",
      "Reference: I have to give Fork a four, only because of the flies outside. We sat in the front promenade area and I legit was playing wack-a-mole/shoo-fly for the ENTIRETY of our meal. It's frustrating when you are trying to eat, enjoy company a do hold conversation. \n",
      "\n",
      "However.....the food. Lord bless the chef, the local farmers, the fertilizers, and I guess Monsanto because there was not one thing we ate that was not touched. I had the BAN Sammy and I nearly proposed to the cute server. The bacon. Lord the bacon. The swine was too divine. It was applewood smoked. Lord knows it was all the apple and all the wood and ALLL the glory in between. The egg, the avocado, the bread the pesto and last but not least the fries! The potatoe capital lived up to it's name. Dusted with Parmesan fried with love. \n",
      "\n",
      "My bestie got the Urban burger. I took a bite and was transcended to beef and brisket glory. She got all the addition and I could not help but plot how I was going to steal a 2nd bite. Lucky for we sharing is caring and the bestie deeeelivered. \n",
      "\n",
      "\n",
      "Lastly, when I thought I would have to roll myself back to the car, we ordered to butter cake as advised. *exhales and hums*. That was THEEEE BEST BUTTER CAKE A LA MODE that forces you into a state of Mindfulness that can only be achieved by a trained monk in seclusion. \n",
      "\n",
      "All that being said. Please Fork it up at Fork.\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.2919\n",
      "  ROUGE-2: 0.0489\n",
      "  ROUGE-L: 0.1568\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.1016\n",
      "  BLEU-2: 0.0398\n",
      "  BLEU-3: 0.0197\n",
      "  BLEU-4: 0.0113\n",
      "\n",
      "Seed: Always exceeds expectations on\n",
      "Generated: Always exceeds expectations on the own right the end i remember looking forward to the bar boise went there and had a part of the right bar but we ate new years ago for 8th street and the food is skimpy in the main course two of them and it jumped kinda awesome and tasty after they first had a drink everyone else zero before bahama single time the first time they were cute you don't plan to get a hot restaurant here seating back at your table the setting is fun but i <OOV> together several minutes area with a open wooden view\n",
      "Reference: Always exceeds expectations on food and service. I go here for every birthday! If you haven't tried their grilled cheese, you haven't lived!\n",
      "ROUGE scores:\n",
      "  ROUGE-1: 0.1692\n",
      "  ROUGE-2: 0.0469\n",
      "  ROUGE-L: 0.1231\n",
      "BLEU scores:\n",
      "  BLEU-1: 0.0865\n",
      "  BLEU-2: 0.0502\n",
      "  BLEU-3: 0.0379\n",
      "  BLEU-4: 0.0264\n",
      "\n",
      "--- AVERAGE ROUGE SCORES ---\n",
      "ROUGE-1: 0.2468\n",
      "ROUGE-2: 0.0562\n",
      "ROUGE-L: 0.1547\n",
      "\n",
      "--- AVERAGE BLEU SCORES ---\n",
      "BLEU-1: 0.1372\n",
      "BLEU-2: 0.0670\n",
      "BLEU-3: 0.0425\n",
      "BLEU-4: 0.0271\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def compute_bleu(reference_text, generated_text):\n",
    "    \"\"\"\n",
    "    Compute BLEU score between reference and generated text.\n",
    "    Uses smoothing to avoid zero scores for short sequences.\n",
    "\n",
    "    Returns a dictionary with BLEU-1 to BLEU-4 scores.\n",
    "    \"\"\"\n",
    "    reference = [reference_text.split()]  # reference must be a list of list of tokens\n",
    "    hypothesis = generated_text.split()   # generated text tokens\n",
    "\n",
    "    smoothie = SmoothingFunction().method4\n",
    "\n",
    "    return {\n",
    "        \"BLEU-1\": sentence_bleu(reference, hypothesis, weights=(1, 0, 0, 0), smoothing_function=smoothie),\n",
    "        \"BLEU-2\": sentence_bleu(reference, hypothesis, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie),\n",
    "        \"BLEU-3\": sentence_bleu(reference, hypothesis, weights=(0.33, 0.33, 0.33, 0), smoothing_function=smoothie),\n",
    "        \"BLEU-4\": sentence_bleu(reference, hypothesis, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_rouge(reference_text, generated_text):\n",
    "    \"\"\"\n",
    "    Compute ROUGE scores between reference and generated text.\n",
    "    Returns a dictionary of ROUGE-1, ROUGE-2, and ROUGE-L scores.\n",
    "    \"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_text, generated_text)\n",
    "    return {\n",
    "        'ROUGE-1': scores['rouge1'].fmeasure,\n",
    "        'ROUGE-2': scores['rouge2'].fmeasure,\n",
    "        'ROUGE-L': scores['rougeL'].fmeasure,\n",
    "    }\n",
    "\n",
    "rouge_totals = {'ROUGE-1': 0, 'ROUGE-2': 0, 'ROUGE-L': 0}\n",
    "bleu_totals = {'BLEU-1': 0, 'BLEU-2': 0, 'BLEU-3': 0, 'BLEU-4': 0}\n",
    "num_samples = 10\n",
    "\n",
    "for i in range(num_samples):\n",
    "    original = reviews[i]\n",
    "    seed = \" \".join(original.split()[:4])\n",
    "    generated = generate(seed, model, tokenizer, max_sequence_len)\n",
    "    \n",
    "    rouge_scores = compute_rouge(original, generated)\n",
    "    bleu_scores = compute_bleu(original, generated)\n",
    "    \n",
    "    print(f\"\\nSeed: {seed}\")\n",
    "    print(f\"Generated: {generated}\")\n",
    "    print(f\"Reference: {original}\")\n",
    "    \n",
    "    print(\"ROUGE scores:\")\n",
    "    for k, v in rouge_scores.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "        rouge_totals[k] += v\n",
    "    \n",
    "    print(\"BLEU scores:\")\n",
    "    for k, v in bleu_scores.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "        bleu_totals[k] += v\n",
    "\n",
    "# Compute and print means\n",
    "print(\"\\n--- AVERAGE ROUGE SCORES ---\")\n",
    "for k in rouge_totals:\n",
    "    print(f\"{k}: {rouge_totals[k]/num_samples:.4f}\")\n",
    "\n",
    "print(\"\\n--- AVERAGE BLEU SCORES ---\")\n",
    "for k in bleu_totals:\n",
    "    print(f\"{k}: {bleu_totals[k]/num_samples:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 150 epoches\n",
    "##### --- AVERAGE ROUGE SCORES ---\n",
    "ROUGE-1: 0.2500\n",
    "ROUGE-2: 0.0608\n",
    "ROUGE-L: 0.1620\n",
    "\n",
    "##### --- AVERAGE BLEU SCORES ---\n",
    "BLEU-1: 0.1559\n",
    "BLEU-2: 0.0736\n",
    "BLEU-3: 0.0480\n",
    "BLEU-4: 0.0307"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7375836,
     "sourceId": 11749099,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7385441,
     "sourceId": 11764170,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 338569,
     "modelInstanceId": 318008,
     "sourceId": 385484,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
